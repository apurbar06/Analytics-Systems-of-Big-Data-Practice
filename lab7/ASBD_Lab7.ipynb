{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install mlxtend --upgrade"
      ],
      "metadata": {
        "id": "SqUu7vKnYz99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "import time\n",
        "import re\n",
        "import itertools\n",
        "import copy\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "bH-zc_6joas7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1\n",
        "#### Test drive the basic version of FP Growth algorithms for Frequent Itemset Mining using the package /\n",
        "library support in the platform of your choice. Test it with various support and confidence measures and\n",
        "generate a time comparison for varied data set sizes. To do the performance comparison you may use\n",
        "benchmark datasets provided for FIM such as the FIMI workshop or other sources."
      ],
      "metadata": {
        "id": "z6scBta4FxV5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fhEHLgr-zBPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019d50ae-0beb-4a14-c655-54dc880ab076"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent itemsets:\n",
            "      support                          itemsets\n",
            "0    0.238368                   (mineral water)\n",
            "1    0.132116                       (green tea)\n",
            "2    0.076523                  (low fat yogurt)\n",
            "3    0.071457                          (shrimp)\n",
            "4    0.065858                       (olive oil)\n",
            "..        ...                               ...\n",
            "720  0.005999               (eggs, french wine)\n",
            "721  0.005199          (chocolate, french wine)\n",
            "722  0.005333          (mineral water, carrots)\n",
            "723  0.005733  (escalope, mushroom cream sauce)\n",
            "724  0.005066      (mineral water, nonfat milk)\n",
            "\n",
            "[725 rows x 2 columns]\n",
            "\n",
            " Time Taken: 0.26431953500000027\n"
          ]
        }
      ],
      "source": [
        "data=pd.read_csv(\"store_data.csv\", header=None)\n",
        "df=pd.DataFrame(data)\n",
        "\n",
        "\n",
        "#creating list\n",
        "records = [[y for y in x if pd.notna(y)] for x in df.values.tolist()] \n",
        "\n",
        "# Convert the data to a transaction database\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(records).transform(records)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# Perform FP-Growth algorithm\n",
        "start = time.process_time()\n",
        "frequent_itemsets = fpgrowth(df, min_support=0.005, use_colnames=True)\n",
        "end = time.process_time()\n",
        "\n",
        "# Print the results\n",
        "print(\"Frequent itemsets:\")\n",
        "print(frequent_itemsets)\n",
        "\n",
        "print(\"\\n Time Taken:\",end-start)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2\n",
        "#### Extend the Apriori Algorithm discussed in the class supporting Transaction Reduction approach to improve the time complexity issue as a result of the repeated scans limitation of Apriori. You may compare this extended version with the earlier implementations in (1) over the same benchmark dataset."
      ],
      "metadata": {
        "id": "oX2MgLGKYMgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"store_data.csv\", header=None)\n",
        "df=pd.DataFrame(data)\n",
        "\n",
        "\n",
        "#creating list\n",
        "records = [[y for y in x if pd.notna(y)] for x in df.values.tolist()]   \n",
        "print(records[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xJyJ1Sz_MvN",
        "outputId": "803f12ee-86fb-4c7e-a48a-3bd35df93188"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['eggs', 'pet food']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the database with tranjaction number\n",
        "Database={}\n",
        "for i in range(len(records)):\n",
        "    Database[\"T\"+str(i+1)]=records[i]\n",
        "\n",
        "\n",
        "# creating C1(itemset with one element) with the count\n",
        "Itemset={}\n",
        "for i in range(len(records)):\n",
        "    for j in range(len(records[i])):\n",
        "        if(frozenset([records[i][j]]) not in Itemset):            # Frozen set is just an immutable version of a Python set object. While elements of a set can be modified at \n",
        "            Itemset[frozenset([records[i][j]])]=1                 # any time, elements of the frozen set remain the same after creation.\n",
        "        else:\n",
        "            Itemset[frozenset([records[i][j]])]+=1\n",
        "print(Itemset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMOyqL_VfLdq",
        "outputId": "cf75808b-2300-4ce8-e5cf-3838272aeb52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{frozenset({'shrimp'}): 536, frozenset({'almonds'}): 153, frozenset({'avocado'}): 250, frozenset({'vegetables mix'}): 193, frozenset({'green grapes'}): 68, frozenset({'whole weat flour'}): 70, frozenset({'yams'}): 86, frozenset({'cottage cheese'}): 239, frozenset({'energy drink'}): 200, frozenset({'tomato juice'}): 228, frozenset({'low fat yogurt'}): 574, frozenset({'green tea'}): 991, frozenset({'honey'}): 356, frozenset({'salad'}): 37, frozenset({'mineral water'}): 1788, frozenset({'salmon'}): 319, frozenset({'antioxydant juice'}): 67, frozenset({'frozen smoothie'}): 475, frozenset({'spinach'}): 53, frozenset({'olive oil'}): 494, frozenset({'burgers'}): 654, frozenset({'meatballs'}): 157, frozenset({'eggs'}): 1348, frozenset({'chutney'}): 31, frozenset({'turkey'}): 469, frozenset({'milk'}): 972, frozenset({'energy bar'}): 203, frozenset({'whole wheat rice'}): 439, frozenset({'whole wheat pasta'}): 221, frozenset({'french fries'}): 1282, frozenset({'soup'}): 379, frozenset({'light cream'}): 117, frozenset({'shallot'}): 58, frozenset({'frozen vegetables'}): 715, frozenset({'spaghetti'}): 1306, frozenset({'pet food'}): 49, frozenset({'cookies'}): 603, frozenset({'cooking oil'}): 383, frozenset({'champagne'}): 351, frozenset({'chocolate'}): 1230, frozenset({'chicken'}): 450, frozenset({'oil'}): 173, frozenset({'fresh tuna'}): 167, frozenset({'tomatoes'}): 513, frozenset({'black tea'}): 107, frozenset({'extra dark chocolate'}): 90, frozenset({'protein bar'}): 139, frozenset({'red wine'}): 211, frozenset({'pasta'}): 118, frozenset({'pepper'}): 199, frozenset({'shampoo'}): 37, frozenset({'rice'}): 141, frozenset({'sparkling water'}): 47, frozenset({'ham'}): 203, frozenset({'body spray'}): 86, frozenset({'pancakes'}): 713, frozenset({'grated cheese'}): 393, frozenset({'white wine'}): 124, frozenset({'toothpaste'}): 61, frozenset({'parmesan cheese'}): 149, frozenset({'fresh bread'}): 323, frozenset({'ground beef'}): 737, frozenset({'escalope'}): 595, frozenset({'herb & pepper'}): 371, frozenset({'tomato sauce'}): 106, frozenset({'magazines'}): 82, frozenset({'strawberries'}): 160, frozenset({'strong cheese'}): 58, frozenset({'pickles'}): 45, frozenset({'cake'}): 608, frozenset({'hot dogs'}): 243, frozenset({'brownies'}): 253, frozenset({'cereals'}): 193, frozenset({'clothes accessories'}): 63, frozenset({'bug spray'}): 65, frozenset({'muffins'}): 181, frozenset({'light mayo'}): 204, frozenset({'gums'}): 101, frozenset({'soda'}): 47, frozenset({'cider'}): 79, frozenset({'corn'}): 36, frozenset({'yogurt cake'}): 205, frozenset({'mint'}): 131, frozenset({'butter'}): 226, frozenset({'asparagus'}): 36, frozenset({'french wine'}): 169, frozenset({'salt'}): 69, frozenset({'tea'}): 29, frozenset({'barbecue sauce'}): 81, frozenset({'mayonnaise'}): 46, frozenset({'zucchini'}): 71, frozenset({'carrots'}): 115, frozenset({'mushroom cream sauce'}): 143, frozenset({'candy bars'}): 73, frozenset({'chili'}): 46, frozenset({'mashed potato'}): 31, frozenset({'nonfat milk'}): 78, frozenset({'water spray'}): 3, frozenset({'chocolate bread'}): 32, frozenset({'mint green tea'}): 42, frozenset({'eggplant'}): 99, frozenset({'blueberries'}): 69, frozenset({'bacon'}): 65, frozenset({'fromage blanc'}): 102, frozenset({'gluten free bar'}): 52, frozenset({'dessert wine'}): 33, frozenset({'flax seed'}): 68, frozenset({'hand protein bar'}): 39, frozenset({'sandwich'}): 34, frozenset({'babies food'}): 34, frozenset({'melons'}): 90, frozenset({'cauliflower'}): 36, frozenset({'green beans'}): 65, frozenset({'ketchup'}): 33, frozenset({'bramble'}): 14, frozenset({'burger sauce'}): 44, frozenset({'oatmeal'}): 33, frozenset({'cream'}): 7, frozenset({'napkins'}): 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Min_Sup_Count=0.005*len(records)\n",
        "Li={}\n",
        "# filtering Itemset whose support is greater than min support\n",
        "for key,val in Itemset.items():\n",
        "    if(val>=Min_Sup_Count):\n",
        "        Li[key]=val\n",
        "Itemset=Li\n",
        "\n",
        "\n",
        "# get the support count(occuring) of the set of items in the Database\n",
        "def check(miniset,Database):\n",
        "    count=0\n",
        "    for key,val in Database.items():\n",
        "        if(frozenset(val).intersection(miniset)==miniset):\n",
        "            count+=1\n",
        "    return count\n",
        "\n",
        "\n",
        "# to get C_(i+1) from L_i\n",
        "def get_c(Li,Database,cur_sot):\n",
        "    c={}\n",
        "    for key,vals in Li.items():\n",
        "        for key1,vals1 in Li.items():\n",
        "            if (key1!=key):\n",
        "                miniset=key1.union(key)\n",
        "                if(len(miniset)>cur_sot):\n",
        "                    continue\n",
        "                count=check(miniset,Database)\n",
        "                c[miniset]=count\n",
        "    return c\n",
        "\n",
        "\n",
        "# to get L_i from C_i\n",
        "def get_l(c,Min_Sup_Count):\n",
        "    rem_keys=[]\n",
        "    for key,val in c.items():\n",
        "        if(val<Min_Sup_Count):\n",
        "            rem_keys.append(key)\n",
        "    for key in rem_keys:\n",
        "        c.pop(key)\n",
        "    return c\n",
        "\n",
        "\n",
        "# this is where we reduce the database. We remove those tranjaction whose size is less\n",
        "def remove_transaction(Database,sot):\n",
        "    rem_keys=[]\n",
        "    for key,val in Database.items():\n",
        "        if(len(val)<sot):\n",
        "            rem_keys.append(key)\n",
        "    for key in rem_keys:\n",
        "        Database.pop(key)\n",
        "    return Database\n",
        "\n",
        "\n",
        "# Item which could not come into current L_i (because their support is less than min support) remove those items from database\n",
        "def remove_item(Li,Database):\n",
        "    miniset=set()\n",
        "    for key,val in Li.items():\n",
        "        miniset=miniset.union(key)\n",
        "    for key,val in Database.items():\n",
        "        Database[key]=list(set(val) & miniset)\n",
        "        \n",
        "    return Database"
      ],
      "metadata": {
        "id": "k3IGQ2FNfVJY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.process_time()\n",
        "\n",
        "Final_List=[]\n",
        "sot=1\n",
        "final_c={}\n",
        "while(1):\n",
        "    Database=remove_transaction(Database,sot)\n",
        "    c=get_c(Li,Database,sot+1)\n",
        "    sot+=1\n",
        "    \n",
        "    Li=get_l(c,Min_Sup_Count)\n",
        "    Database=remove_item(Li,Database)\n",
        "    if(len(Li)==0):\n",
        "        break\n",
        "    else:\n",
        "        final_c=Li\n",
        "\n",
        "end = time.process_time()\n",
        "\n",
        "print(\"Total iteration: \" + str(sot))\n",
        "print(\"min_support: \" + str(Min_Sup_Count))\n",
        "print(\"\\n Time Taken with transjaction reduction  \"+str(end-start)+\" seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keYx5CUYmdUw",
        "outputId": "ba1cbe02-c6ba-4cda-9ebb-e52026f0d2c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total iteration: 4\n",
            "min_support: 37.505\n",
            "\n",
            " Time Taken with transjaction reduction  122.93064487400001 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3\n",
        "#### Test drive any one implementation in (1) or (2) adopting a Vertical Transaction Database format."
      ],
      "metadata": {
        "id": "CrYhVi53wTjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records=[[100,400,500,700,800,900],[100,200,300,400,600,800,900],[300,500,600,700,800,900],[200,400],[100,800]]\n",
        "\n",
        "\n",
        "Database={}\n",
        "for i in range(len(records)):\n",
        "    Database[\"T\"+str(i+1)]=records[i]\n",
        "\n",
        "Itemset={}\n",
        "for i in range(len(records)):\n",
        "    for j in range(len(records[i])):\n",
        "        if(frozenset([records[i][j]]) not in Itemset):\n",
        "            Itemset[frozenset([records[i][j]])]=1\n",
        "        else:\n",
        "            Itemset[frozenset([records[i][j]])]+=1\n",
        "\n",
        "\n",
        "\n",
        "# creating  virtical format where each row will contain those tranjaction numbers where that item set is present\n",
        "Database_vdf={}\n",
        "for key,val in Database.items():\n",
        "    for x in val:\n",
        "        if(frozenset([x]) not in Database_vdf):\n",
        "            Database_vdf[frozenset([x])]=frozenset([key])\n",
        "        else:\n",
        "            Database_vdf[frozenset([x])]=frozenset([key]).union(Database_vdf[frozenset([x])])\n",
        "\n",
        "\n",
        "records_vdf=[]\n",
        "for key,val in Database_vdf.items():\n",
        "    records_vdf.append(val)\n",
        "\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(records_vdf).transform(records_vdf)\n",
        "df_vdf = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "\n",
        "start = time.process_time()\n",
        "\n",
        "print(apriori(df_vdf, min_support=0.003,use_colnames=True))\n",
        "\n",
        "time_taken=time.process_time() - start\n",
        "print(\"\\n Time Taken for Mining using Apriori =\",time_taken)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0m2GXOfuzKz",
        "outputId": "49e369c0-5b18-418e-c3a1-acc3bd3cd62d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     support          itemsets\n",
            "0   0.666667              (T1)\n",
            "1   0.777778              (T2)\n",
            "2   0.666667              (T3)\n",
            "3   0.222222              (T4)\n",
            "4   0.222222              (T5)\n",
            "5   0.444444          (T1, T2)\n",
            "6   0.444444          (T1, T3)\n",
            "7   0.111111          (T4, T1)\n",
            "8   0.222222          (T5, T1)\n",
            "9   0.444444          (T3, T2)\n",
            "10  0.222222          (T4, T2)\n",
            "11  0.222222          (T5, T2)\n",
            "12  0.111111          (T5, T3)\n",
            "13  0.222222      (T3, T1, T2)\n",
            "14  0.111111      (T4, T1, T2)\n",
            "15  0.222222      (T5, T1, T2)\n",
            "16  0.111111      (T5, T1, T3)\n",
            "17  0.111111      (T5, T3, T2)\n",
            "18  0.111111  (T5, T3, T1, T2)\n",
            "\n",
            " Time Taken for Mining using Apriori = 0.020376107999993565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4\n",
        "#### Using a vertical transaction database notation, generate the FI’s following the intersection approach (basic ECLAT) discussed in the class. Use earlier benchmark datasets in (1)."
      ],
      "metadata": {
        "id": "c3qe1FzYUcSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"store_data.csv\", header=None)\n",
        "df=pd.DataFrame(data)\n",
        "\n",
        "records = [[y for y in x if pd.notna(y)] for x in df.values.tolist()]\n",
        "\n",
        "Database={}\n",
        "for i in range(len(records)):\n",
        "    Database[\"T\"+str(i+1)]=records[i]\n",
        "\n",
        "\n",
        "# Scan the Dataset to convert to vertical form\n",
        "Database_vdf={}\n",
        "for key,val in Database.items():\n",
        "    for x in val:\n",
        "        if(frozenset([x]) not in Database_vdf):\n",
        "            Database_vdf[frozenset([x])]=frozenset([key])\n",
        "        else:\n",
        "            Database_vdf[frozenset([x])]=frozenset([key]).union(Database_vdf[frozenset([x])])\n",
        "\n",
        "\n",
        "# to remove items less than min support\n",
        "def remove_items_vdf(Database_vdf,Min_Sup):\n",
        "    rem_keys=[]\n",
        "    for key,val in Database_vdf.items():\n",
        "        if(len(val)<Min_Sup):\n",
        "            rem_keys.append(key)\n",
        "    for key in rem_keys:\n",
        "        Database_vdf.pop(key)\n",
        "    return Database_vdf\n",
        "\n",
        "\n",
        "def get_C(Ci,iteration):\n",
        "    New_Ci={}\n",
        "    for key1,val1 in Ci.items():\n",
        "        for key2,val2 in Ci.items():\n",
        "            if(key1!=key2):\n",
        "                new_key=key1.union(key2)\n",
        "                if(len(new_key)>iteration):\n",
        "                    continue\n",
        "                else:\n",
        "                    New_Ci[new_key]=val1.intersection(val2)\n",
        "    return New_Ci\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "start = time.process_time()\n",
        "Min_Sup_Count_vdf=0.005*len(records)\n",
        "\n",
        "Li=remove_items_vdf(Database_vdf,Min_Sup_Count_vdf)\n",
        "count=1\n",
        "while(1):\n",
        "    count+=1\n",
        "    c=get_C(Li,count)\n",
        "    Li=remove_items_vdf(c,Min_Sup_Count_vdf)\n",
        "    if(len(Li)==0):\n",
        "        break\n",
        "    else:\n",
        "        final_vdf=Li\n",
        "\n",
        "end = time.process_time()\n",
        "print(\"Total iteration: \" + str(count-1))\n",
        "print(\"min_support: \" + str(Min_Sup_Count_vdf))\n",
        "print(\"Time Taken with transjaction reduction  \"+str(end-start)+\" seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBZwFG0dUkgo",
        "outputId": "1ef95506-d079-4856-83cc-1f3a6d1e1b8b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total iteration: 3\n",
            "min_support: 37.505\n",
            "Time Taken with transjaction reduction  0.29762266400001636 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5\n",
        "#### Extend the basic Apriori algorithm to generate Frequent Patterns which differentiate ab from ba (ordered patterns generation)."
      ],
      "metadata": {
        "id": "vVw4RVcZyiUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to get C_(i+1) form L_i\n",
        "def get_c(l0,sequences,cur_sot):\n",
        "    c1={}\n",
        "    for key1 in l0.keys():\n",
        "        for key2 in l0.keys():\n",
        "            if(key1!=key2):\n",
        "                new_key=key1+key2\n",
        "                if(len(new_key)==cur_sot):\n",
        "                    # below part will get the support count of the new_key\n",
        "                    for key in sequences.keys():\n",
        "                        if(new_key not in c1):\n",
        "                            c1[new_key]=len(re.findall(new_key,sequences[key]))\n",
        "                        else:\n",
        "                            c1[new_key]+=len(re.findall(new_key,sequences[key]))\n",
        "    return c1\n",
        "                    \n",
        "\n",
        "# To get L_i from C_i                   \n",
        "def get_l(c,Min_Sup_Count):\n",
        "    Li={}\n",
        "    for key in c.keys():\n",
        "        if(c[key]>=Min_Sup_Count):\n",
        "            Li[key]=c[key]\n",
        "    return Li"
      ],
      "metadata": {
        "id": "oJSbHK9s1WzP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transaction={1: 'aabcbacdcf', 2: 'adcabacae', 3: 'efabadfcb', 4: 'egbafcbc'}\n",
        "\n",
        "\n",
        "c0={}\n",
        "for key in Transaction.keys():\n",
        "    for x in Transaction[key]:\n",
        "            if(x not in c0):\n",
        "                c0[x]=1\n",
        "            else:\n",
        "                c0[x]+=1\n",
        "\n",
        "l0={}\n",
        "Min_Sup_Count=1\n",
        "for key in c0.keys():\n",
        "    if(c0[key]>=Min_Sup_Count):\n",
        "        l0[key]=c0[key]\n",
        "\n",
        "\n",
        "sot=1\n",
        "final_sequence={}\n",
        "Min_Sup_Count=3\n",
        "while(1):\n",
        "    c=get_c(l0,Transaction,sot+1)\n",
        "    sot+=1\n",
        "    Li=get_l(c,Min_Sup_Count)\n",
        "    if(len(Li)==0):\n",
        "        break\n",
        "    else:\n",
        "        final_sequence=Li\n",
        "\n",
        "\n",
        "print(\"Total iteration: \" + str(sot-1))\n",
        "print(\"Frequent Patterns are:\",[x for x in final_sequence.keys()] )\n",
        "# int the output we can see both ab and ba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akkwvWlT1dJm",
        "outputId": "4281bd56-d7b9-4f9d-a270-0c6c8be7840e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total iteration: 2\n",
            "Frequent Patterns are: ['ab', 'ba', 'cb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6\n",
        "#### Implement following extensions to Apriori Algorithm (discussed / to be discussed in the class): Hash based strategy, Partitioning Approach. You may refer to online tutorials for a formal pseudocode description."
      ],
      "metadata": {
        "id": "DbAZdL7n8N1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### -> Hash based"
      ],
      "metadata": {
        "id": "Q4liybIomivh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = [{'A','C','D'},{'B','C','E'},{'A','B','C','E'},{'B','E'}]\n",
        "\n",
        "database_hash={}\n",
        "count=0\n",
        "for i in transactions:\n",
        "    count+=1\n",
        "    database_hash[\"T\"+str(count)]=i\n",
        "\n",
        "c0={}\n",
        "for i in transactions:\n",
        "    for j in i:\n",
        "        if(j in c0):\n",
        "            c0[j]+=1\n",
        "        else:\n",
        "            c0[j]=1\n",
        "      \n",
        "c0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfAxbd8E8m7Z",
        "outputId": "4c153d50-bab6-4183-f13d-ae2d40ea9c6b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 2, 'C': 3, 'D': 1, 'B': 3, 'E': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Min_Sup_Count=2\n",
        "rem_keys=[]\n",
        "Li={}\n",
        "for key,val in c0.items():\n",
        "    if(val>=Min_Sup_Count):\n",
        "        Li[key]=val\n",
        "        rem_keys.append(key)\n",
        "\n",
        "Li"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMSRk2Q5aL5r",
        "outputId": "049e5a63-46fd-47ef-a65e-209be703ada6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 2, 'C': 3, 'B': 3, 'E': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating combinations of two elements for each transaction\n",
        "for key,val in database_hash.items():\n",
        "    val=[set(i) for i in itertools.combinations(val, 2)]\n",
        "    sets=[]\n",
        "    for i in range(len(val)):\n",
        "        sets.append(sorted(val[i]))\n",
        "\n",
        "    database_hash[key]=sets\n",
        "database_hash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9ZTvNXgbyzN",
        "outputId": "50677917-82a4-4e03-db7c-342be8932c68"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'T1': [['A', 'C'], ['A', 'D'], ['C', 'D']],\n",
              " 'T2': [['B', 'C'], ['B', 'E'], ['C', 'E']],\n",
              " 'T3': [['A', 'B'],\n",
              "  ['A', 'C'],\n",
              "  ['A', 'E'],\n",
              "  ['B', 'C'],\n",
              "  ['B', 'E'],\n",
              "  ['C', 'E']],\n",
              " 'T4': [['B', 'E']]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# order will be used to generate hash table\n",
        "order={}\n",
        "count=0\n",
        "for key in sorted(c0.keys()):\n",
        "    count+=1\n",
        "    order[key]=count\n",
        "order"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYjfFPCdcNvP",
        "outputId": "42b2d40d-ea4e-40bf-8e6c-76db337540db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate hash table\n",
        "Hash_Table={}\n",
        "for key,items in database_hash.items():\n",
        "    for x in items:\n",
        "        val=(order[x[0]]*10+order[x[1]])%7\n",
        "        if(val in Hash_Table):\n",
        "            Hash_Table[val].append(x)\n",
        "        else:\n",
        "            Hash_Table[val]=[x]\n",
        "Hash_Table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMPXStQ_cewQ",
        "outputId": "b6cd3f40-b08e-4512-ab65-69ace87b4018"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: [['A', 'C'], ['C', 'D'], ['A', 'C']],\n",
              " 0: [['A', 'D'], ['C', 'E'], ['C', 'E']],\n",
              " 2: [['B', 'C'], ['B', 'C']],\n",
              " 4: [['B', 'E'], ['B', 'E'], ['B', 'E']],\n",
              " 5: [['A', 'B']],\n",
              " 1: [['A', 'E']]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate C2 using hash table\n",
        "C2={}\n",
        "keys=sorted(Li.keys())\n",
        "for i in range(len(keys)):\n",
        "    for j in range(i+1,len(keys)):\n",
        "        New_key=[keys[i], keys[j]]\n",
        "        New_val=(order[keys[i]]*10+order[keys[j]])%7\n",
        "        if(len(Hash_Table[New_val]) >= Min_Sup_Count):                          # if total item count in the hash table in that index is less than min support count \n",
        "            C2[frozenset(New_key)]=Hash_Table[New_val].count(New_key)           # then it is confirmed that support count of that item set must be less than min support count\n",
        "print(C2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP9oa-KadPfX",
        "outputId": "1fb58e90-f481-4daa-eb2e-2fa7e00ef516"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{frozenset({'A', 'C'}): 2, frozenset({'B', 'C'}): 2, frozenset({'B', 'E'}): 3, frozenset({'C', 'E'}): 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate L2\n",
        "L2={}\n",
        "for key,val in C2.items():\n",
        "    if(val>=Min_Sup_Count):\n",
        "        L2[key]=val\n",
        "\n",
        "print(L2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-nX5S7OfJby",
        "outputId": "985e02f0-2c4e-4f3b-d29f-4a8be86f02fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{frozenset({'A', 'C'}): 2, frozenset({'B', 'C'}): 2, frozenset({'B', 'E'}): 3, frozenset({'C', 'E'}): 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### -> Partitioning Approach"
      ],
      "metadata": {
        "id": "julFtiurjWbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"store_data.csv\", header=None)\n",
        "df=pd.DataFrame(data)\n",
        "\n",
        "records = [[y for y in x if pd.notna(y)] for x in df.values.tolist()]\n",
        "\n",
        "Database={}\n",
        "for i in range(len(records)):\n",
        "    Database[\"T\"+str(i+1)]=records[i]\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(records).transform(records)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "\n",
        "# devide the dataset into 13 partitions\n",
        "dfs=[]\n",
        "for i in range(0,df.shape[0],int(df.shape[0]/13)):\n",
        "    dfs.append(df.iloc[i:i+int(df.shape[0]/13)])\n",
        "\n",
        "\n",
        "# calculating apriori of each partition\n",
        "results=[]\n",
        "for i in dfs:\n",
        "    results.append(apriori(i, min_support=0.01,use_colnames=True))\n",
        "  \n",
        "results[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "y4yOwI4qjgk-",
        "outputId": "16cd1100-ab78-47ae-cce7-6034863923f8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      support                              itemsets\n",
              "0    0.025997                             (almonds)\n",
              "1    0.010399                   (antioxydant juice)\n",
              "2    0.029463                             (avocado)\n",
              "3    0.012132                          (body spray)\n",
              "4    0.017331                            (brownies)\n",
              "..        ...                                   ...\n",
              "316  0.012132        (pasta, mineral water, shrimp)\n",
              "317  0.012132      (soup, mineral water, spaghetti)\n",
              "318  0.010399       (soup, mineral water, tomatoes)\n",
              "319  0.010399            (pasta, shrimp, spaghetti)\n",
              "320  0.012132  (pasta, mineral water, eggs, shrimp)\n",
              "\n",
              "[321 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1be37d8-e93a-481f-9853-97781d60660f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>support</th>\n",
              "      <th>itemsets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.025997</td>\n",
              "      <td>(almonds)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.010399</td>\n",
              "      <td>(antioxydant juice)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.029463</td>\n",
              "      <td>(avocado)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.012132</td>\n",
              "      <td>(body spray)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.017331</td>\n",
              "      <td>(brownies)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>0.012132</td>\n",
              "      <td>(pasta, mineral water, shrimp)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>0.012132</td>\n",
              "      <td>(soup, mineral water, spaghetti)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>0.010399</td>\n",
              "      <td>(soup, mineral water, tomatoes)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>0.010399</td>\n",
              "      <td>(pasta, shrimp, spaghetti)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>0.012132</td>\n",
              "      <td>(pasta, mineral water, eggs, shrimp)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>321 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1be37d8-e93a-481f-9853-97781d60660f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1be37d8-e93a-481f-9853-97781d60660f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1be37d8-e93a-481f-9853-97781d60660f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the part where we combine all parts\n",
        "final_candidate_set={}\n",
        "for i in results:\n",
        "    for j in range(i.shape[0]):\n",
        "        item=i.iloc[j][1]\n",
        "        if(item in final_candidate_set):\n",
        "            final_candidate_set[item]+=(i.iloc[j][0]*int(df.shape[0]/13))    # support count = support * number of rows in i\n",
        "        else:\n",
        "            final_candidate_set[item]=(i.iloc[j][0]*int(df.shape[0]/13))\n",
        "\n",
        "\n",
        "\n",
        "final_results={}\n",
        "Min_Sup_Count=int(df.shape[0]*(0.1))\n",
        "for key,val in final_candidate_set.items():\n",
        "    if(val>=Min_Sup_Count):\n",
        "        final_results[key]=val\n",
        "final_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFgRA-xFl7D-",
        "outputId": "b223dafd-82af-44dc-f10f-f58d45eb590f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{frozenset({'chocolate'}): 1229.0,\n",
              " frozenset({'eggs'}): 1348.0,\n",
              " frozenset({'french fries'}): 1282.0,\n",
              " frozenset({'green tea'}): 991.0,\n",
              " frozenset({'milk'}): 972.0,\n",
              " frozenset({'mineral water'}): 1788.0,\n",
              " frozenset({'spaghetti'}): 1306.0}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7\n",
        "#### Implement the Dynamic Itemset Counting Algorithm for Frequent Itemset Generation."
      ],
      "metadata": {
        "id": "jZJ-H0QJmxUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to get all subset of length n\n",
        "def get_subset(S,n):\n",
        "    a = itertools.combinations(S,n)\n",
        "    results = []\n",
        "    for i in a:\n",
        "        results.append(set(i))\n",
        "    return(results)\n",
        "\n",
        "\n",
        "# try to append items in unique_itemset with set S\n",
        "def get_superset(S,unique_itemset):\n",
        "    result = []\n",
        "    a = set()\n",
        "    for i in unique_itemset:\n",
        "        # print(\"get_superset1 \", S, i, i.intersection(S), i.union(S))\n",
        "        if i.intersection(S)==set():              # check wheather the intersection is null\n",
        "            a = i.union(S)\n",
        "            result.append(a)\n",
        "            a = set()\n",
        "\n",
        "    return(result)\n",
        "\n",
        "\n",
        "# check if every possible subset(length less than 1) of Set is subset of frequent_set\n",
        "def check_subset(Set,frequent_set):\n",
        "    subset = get_subset(Set,len(Set)-1)\n",
        "    flag = 1\n",
        "    temp = []\n",
        "\n",
        "    for i in frequent_set:\n",
        "        temp.append(i[0])\n",
        "\n",
        "    frequent_set = temp\n",
        "    for i in subset:\n",
        "        if i not in frequent_set:\n",
        "            flag=0\n",
        "            break\n",
        "\n",
        "    if flag:\n",
        "        return(True)\n",
        "    else:\n",
        "        return(False)\n",
        "\n",
        "\n",
        "# return itemsets which is set to 1 in the transaction\n",
        "def get_itemset(T):\n",
        "    result = set()\n",
        "    for i in range(len(T)):\n",
        "        if T[i]!=0:\n",
        "            result.add(i+1)\n",
        "\n",
        "    return(result)"
      ],
      "metadata": {
        "id": "QsmlTT7IneEx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "database = [[1,1,0],[1,0,0],[0,1,1],[0,0,0]]\n",
        "unique_itemset =[{1},{2},{3}]\n",
        "min_supp = 1\n",
        "M = 2\n",
        "size = len(database)\n",
        "\n",
        "\n",
        "DC = []          # Dashed circle: suspected infrequent itemset\n",
        "DS = []          # Dashed square: suspected frequent itemset\n",
        "SC = []          # Solid circle: confirmed infrequent itemset\n",
        "SS = []          # Solid square: confirmed frequent itemset\n",
        "\n",
        "for i in unique_itemset:\n",
        "    DC.append([i,0,0])        # [item_ser, support_count, count_to_trace_full_scan]\n",
        "\n",
        "print(\"Initial DC:\",DC,\"\\n\")\n",
        "\n",
        "counter = 0\n",
        "T = []\n",
        "while len(DC)!=0 or len(DS)!=0:\n",
        "\n",
        "    for i in range(counter,counter+M):\n",
        "        index = i%size\n",
        "        T = get_itemset(database[index])\n",
        "        print(\"Transaction :\",T)\n",
        "\n",
        "        for item in DC:\n",
        "            item[2]+=1\n",
        "            if item[0].issubset(T):\n",
        "                item[1]+=1                # increase support count\n",
        "        for item in DS:\n",
        "            item[2]+=1\n",
        "            if item[0].issubset(T):\n",
        "                item[1]+=1\n",
        "\n",
        "    for item in copy.copy(DC):\n",
        "        if(item[1]>=min_supp):        \n",
        "            DS.append(item)             # suspected infrequent to suspected frequent\n",
        "            DC.remove(item)\n",
        "\n",
        "    for item in copy.copy(DS):\n",
        "        if(item[2]==size):              # if we scaned the full dataset for this item\n",
        "            SS.append(item)             # suspected frequent to confirmed frequent\n",
        "            DS.remove(item)\n",
        "\n",
        "    for item in copy.copy(DC): \n",
        "        if(item[2]==size):              # done full scan\n",
        "            SC.append(item)             # suspected infrequent to confirmed infrequent\n",
        "            DC.remove(item)\n",
        "\n",
        "    frequent_set = copy.copy(DS)\n",
        "    frequent_set.extend(SS)            # frequent_set will contain both suspected and confirmed frequent\n",
        "    for item in frequent_set:\n",
        "        S = get_superset(item[0],unique_itemset)      # try to append A/B/C with the current item set\n",
        "        for i in S:\n",
        "            if (check_subset(i,frequent_set)):     # check if every possible subset(length less than 1) of i is subset of frequent_set (antimonotonicity property)\n",
        "                flag=1\n",
        "                for x in DC:\n",
        "                    if x[0]==i:\n",
        "                        flag=0\n",
        "                for x in DS:\n",
        "                    if x[0]==i:\n",
        "                        flag=0\n",
        "                for x in SC:\n",
        "                    if x[0]==i:\n",
        "                        flag=0\n",
        "                for x in SS:\n",
        "                    if x[0]==i:\n",
        "                        flag=0\n",
        "                if flag:                     # if we don't find the i\n",
        "                    DC.append([i,0,0])\n",
        "\n",
        "\n",
        "    counter+=M\n",
        "    print(\"DS: \",DS)\n",
        "    print(\"DC: \",DC)\n",
        "    print(\"SS: \",SS)\n",
        "    print(\"SC: \",SC,\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGaPpt4cpepS",
        "outputId": "e9d1c1f5-07a1-412a-f1aa-25404c01260b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial DC: [[{1}, 0, 0], [{2}, 0, 0], [{3}, 0, 0]] \n",
            "\n",
            "Transaction : {1, 2}\n",
            "Transaction : {1}\n",
            "DS:  [[{1}, 2, 2], [{2}, 1, 2]]\n",
            "DC:  [[{3}, 0, 2], [{1, 2}, 0, 0]]\n",
            "SS:  []\n",
            "SC:  [] \n",
            "\n",
            "Transaction : {2, 3}\n",
            "Transaction : set()\n",
            "DS:  []\n",
            "DC:  [[{1, 2}, 0, 2], [{1, 3}, 0, 0], [{2, 3}, 0, 0]]\n",
            "SS:  [[{1}, 2, 4], [{2}, 2, 4], [{3}, 1, 4]]\n",
            "SC:  [] \n",
            "\n",
            "Transaction : {1, 2}\n",
            "Transaction : {1}\n",
            "DS:  []\n",
            "DC:  [[{1, 3}, 0, 2], [{2, 3}, 0, 2]]\n",
            "SS:  [[{1}, 2, 4], [{2}, 2, 4], [{3}, 1, 4], [{1, 2}, 1, 4]]\n",
            "SC:  [] \n",
            "\n",
            "Transaction : {2, 3}\n",
            "Transaction : set()\n",
            "DS:  []\n",
            "DC:  []\n",
            "SS:  [[{1}, 2, 4], [{2}, 2, 4], [{3}, 1, 4], [{1, 2}, 1, 4], [{2, 3}, 1, 4]]\n",
            "SC:  [[{1, 3}, 0, 4]] \n",
            "\n"
          ]
        }
      ]
    }
  ]
}